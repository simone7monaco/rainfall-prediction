{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "splitdir = Path(\"/media/monaco/DATA1/case_study/24h_10mmMAX_OI/split\")\n",
    "convective = pd.read_csv(splitdir / \"cluster_convective.csv\", sep=\";\")\n",
    "intermediate = pd.read_csv(splitdir / \"cluster_intermediate.csv\", sep=\";\")\n",
    "stratiform = pd.read_csv(splitdir / \"cluster_stratiform.csv\", sep=\";\")\n",
    "\n",
    "dates = pd.concat([\n",
    "    convective.assign(NAME=\"convective\"),\n",
    "    intermediate.assign(NAME=\"intermediate\"),\n",
    "    stratiform.assign(NAME=\"stratiform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 45 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=9, random_state=42, shuffle=True)\n",
    "n_split = 2\n",
    "train_index, test_index = list(skf.split(dates, dates.NAME))[n_split]\n",
    "val_index, train_index = np.split(train_index, [len(test_index)])\n",
    "\n",
    "print(len(train_index), len(val_index), len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning_logs/unet/split_5\n",
      "lightning_logs/unet/split_3\n",
      "lightning_logs/ensemble_unet/split_1\n",
      "lightning_logs/ensemble_unet/split_3\n",
      "lightning_logs/sde_unet/split_5\n",
      "lightning_logs/sde_unet/split_3\n"
     ]
    }
   ],
   "source": [
    "respath = Path(\"lightning_logs\")\n",
    "for model in respath.glob(\"[!_]*\"):\n",
    "    for split in model.glob(\"split_*\"):\n",
    "        for predpath in (split / \"test_images\").glob(\"_pred.png\"):\n",
    "            pred = Image.open(predpath).convert(\"L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-distribution detection for regression on the dataset, where OoD are some extreme events hidden at train time.\n",
    "We report the average performance and standard deviation for 9 random splits. All the  model performance is compared in terms of RMSE, AUROC, and AUPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAY ATTENTION THAT THIS IS DONE FOR THE n REPETITIONS OF THE PROBABILISTIC MODEL, EACH RETURNING A METRIC VALUE OVER WHICH WE CALCULATE THE MEAN AND STD\n",
    "import torch\n",
    "\n",
    "def calc_RMSE(pred_mean: torch.Tensor, target_img: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    preds_mean and pred_std have shape (N, 1, H, W), target has shape (N, 1, H, W)\n",
    "    \"\"\"\n",
    "    return torch.sqrt(((pred_mean - target_img) ** 2).mean())\n",
    "\n",
    "def calc_AUROC(pred_variance: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    preds_mean and pred_std have shape (N, 1, H, W), target has shape (N) and is a binary tensor saying if the nth event is an OoD one\n",
    "    AUROC is calculated assigning a label to each prediction based on the average variance over all the pixels of the image\n",
    "    \"\"\"\n",
    "    avg_variance = pred_variance.mean(dim=(1, 2, 3))\n",
    "    curve_steps = 1000\n",
    "    auroc = 0\n",
    "    fprTemp = 1\n",
    "    for delta in torch.arange(avg_variance.min(), avg_variance.max(), (avg_variance.max() - avg_variance.min()) / curve_steps):\n",
    "        tpr = (avg_variance > delta).float().eq(target).float().mean()\n",
    "        fpr = (avg_variance > delta).float().ne(target).float().mean()\n",
    "        auroc += (fprTemp - fpr) * tpr\n",
    "        fprTemp = fpr\n",
    "\n",
    "def calc_AUPR_out(pred_variance: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    preds_mean and pred_std have shape (N, 1, H, W), target has shape (N) and is a binary tensor saying if the nth event is an OoD one\n",
    "    AUPR is calculated assigning a label to each prediction based on the average variance over all the pixels of the image\n",
    "    \"\"\"\n",
    "    avg_variance = pred_variance.mean(dim=(1, 2, 3))\n",
    "    curve_steps = 1000\n",
    "    aupr = 0\n",
    "    recallTemp = 1\n",
    "    for delta in torch.arange(avg_variance.min(), avg_variance.max(), (avg_variance.max() - avg_variance.min()) / curve_steps):\n",
    "        precision = (avg_variance > delta).float().ne(target).float().mean()\n",
    "        recall = (avg_variance > delta).float().ne(target).float().mean()\n",
    "        aupr += (recallTemp - recall) * precision\n",
    "        recallTemp = recall\n",
    "\n",
    "def calc_AUPR_in(pred_variance: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    target = target.eq(0).float()\n",
    "    return calc_AUPR_out(pred_variance, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import NWPDataset\n",
    "from utils import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "class ExtremeDataset(NWPDataset):\n",
    "    \"\"\"\n",
    "    Wrapper of NWPDataset returning the extreme events and the test events for the current split,\n",
    "    together with a boolean label indicating if the event is extreme or not.\n",
    "    \"\"\"\n",
    "    def __init__(self, split_idx, transform=None, seed=42,\n",
    "                 input_path=Path(\"/media/monaco/DATA1/case_study/24h_10mmMAX_OI\")):\n",
    "        case_study = input_path.stem\n",
    "        case_study_max, available_models, _, _, test_dates, indices_one, indices_zero, _, _, _ = io.get_casestudy_stuff(\n",
    "\t\t\tinput_path, n_split=split_idx, case_study=case_study, ispadded=True,\n",
    "\t\t\tseed=seed)\n",
    " \n",
    "        extreme_events = pd.concat([pd.read_csv(exev, header=None) for exev in input_path.glob('*extremeEvents.csv')])[0].values\n",
    "        not_extreme_events = np.array([date for date in test_dates if date not in extreme_events])\n",
    "        all_dates = np.concatenate([extreme_events, not_extreme_events])\n",
    "        self.labels = torch.cat([torch.ones(len(extreme_events)), torch.zeros(len(not_extreme_events))]).long()\n",
    "\n",
    "        X, Y, _, _ = io.load_data(input_path, all_dates, case_study_max, \n",
    "                                                       indices_one, indices_zero, available_models)\n",
    "        super().__init__((torch.from_numpy(X), torch.from_numpy(Y).unsqueeze(1), \n",
    "                          torch.from_numpy(all_dates)), transform=transform)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return super().__getitem__(index) | {'isextreme_label': self.labels[index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.03339843751"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '1.0333984375.1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '0.6759765625000006'\n",
    "fixed_float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 116), (96, 116))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/24h_10mmMAX_OI/obs/data_extremeEvents/new_dataset/OI_20220727_regrid.csv\", sep=\";\", header=None).to_numpy()\n",
    "df1 = pd.read_csv(\"data/24h_10mmMAX_OI/obs/data/OI_20180606_regrid.csv\", sep=\";\", header=None).to_numpy()\n",
    "df.shape, df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 116)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OI_20220727_regrid'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20220606, 20220701, 20220727, 20220906, 20220909, 20220928,\n",
       "       20221001, 20221223, 20230413, 20230516, 20230703, 20230825,\n",
       "       20230912, 20231113, 20231114, 20240318])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path(\"/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI/obs/data_extremeEvents/new_dataset\")\n",
    "# for val in path.glob(\"*csv\"):\n",
    "#     df = pd.read_csv(val, sep=\";\", header=None)\n",
    "#     # for each value, if it is a string with 2 dots in it, remove the second one, joining the previous and the after part and parse the string as a float\n",
    "#     def fixed_float(x):\n",
    "#         if isinstance(x, str) and x.count(\".\") == 2:\n",
    "#             return float(''.join(x.rsplit(\".\", 1)))\n",
    "#         return x\n",
    "#     df.map(fixed_float).to_csv(val, sep=\";\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_events[extreme_events < 20220000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.array([int(p.stem.split('_')[1]) for p in Path(\"data/24h_10mmMAX_OI/obs/data_extremeEvents/new_dataset/\").iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "for nwp in ['bol00', 'c2200', 'c5m00', 'e1000']:\n",
    "    r.append(np.array([int(p.stem.split('_')[1]) for p in Path(\"data/24h_10mmMAX_OI/models/data_extremeEvents/new_dataset/\").glob(f'{nwp}*regrid.csv')]))\n",
    "    print(len(set(r[-1]).intersection(pd.read_csv(input_path/'OI_20222024_10mmMAX_extremeEvents.csv', header=None)[0].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20220523, 20220606, 20220701, 20220727, 20220906, 20220909,\n",
       "       20220928, 20221001, 20221223, 20230413, 20230516, 20230703,\n",
       "       20230825, 20230912, 20231113, 20231114, 20240318])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_events[extreme_events > 20220000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File 'OI*20220906*.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m not_extreme_events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m test_dates \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m extreme_events])\n\u001b[1;32m     10\u001b[0m all_dates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([extreme_events, not_extreme_events])\n\u001b[0;32m---> 11\u001b[0m X, Y, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mindices_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:85\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(topdir, dates, case_study_max, indices, indices_zero, available_models)\u001b[0m\n\u001b[1;32m     83\u001b[0m     _models_tmp\u001b[38;5;241m.\u001b[39mappend(_mdl_data)\n\u001b[1;32m     84\u001b[0m models_data\u001b[38;5;241m.\u001b[39mappend(_models_tmp)\n\u001b[0;32m---> 85\u001b[0m _obs_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m _obs_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mhstack((_obs_data,np\u001b[38;5;241m.\u001b[39mzeros((_obs_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(_obs_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))) \u001b[38;5;241m-\u001b[39m _obs_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))))\n\u001b[1;32m     87\u001b[0m _obs_data[indices_zero] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:56\u001b[0m, in \u001b[0;36mget_obs\u001b[0;34m(topdir, date, case_study_max)\u001b[0m\n\u001b[1;32m     54\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_extremeEvents\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_study\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_regrid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_study\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m obs_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_data \u001b[38;5;241m/\u001b[39m case_study_max\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File 'OI*20220906*.csv' does not exist"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "input_path=Path(\"/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI\")\n",
    "case_study = input_path.stem\n",
    "seed = 42\n",
    "case_study_max, available_models, _, _, test_dates, indices_one, indices_zero, _, _, _ = io.get_casestudy_stuff(\n",
    "\t\t\tinput_path, n_split=1, case_study=case_study, ispadded=True,\n",
    "\t\t\tseed=seed)\n",
    "extreme_events = pd.concat([pd.read_csv(exev, header=None) for exev in input_path.glob('*extremeEvents.csv')])[0].values\n",
    "not_extreme_events = np.array([date for date in test_dates if date not in extreme_events])\n",
    "all_dates = np.concatenate([extreme_events, not_extreme_events])\n",
    "X, Y, _, _ = io.load_data(input_path, all_dates, case_study_max, \n",
    "                                                       indices_one, indices_zero, available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_args\n",
    "args = get_args(['--network_model', 'unet', '-e', '1'])\n",
    "from base_segmodel import _SegmentationModel\n",
    "\n",
    "args.input_path = input_path\n",
    "self = _SegmentationModel(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.hparams.input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_study_max, available_models, train_dates, val_dates, test_dates, indices_one, indices_zero, mask, nx, ny = io.get_casestudy_stuff(\n",
    "\t\t\tself.hparams.input_path, n_split=self.hparams.n_split, case_study=self.hparams.case_study, ispadded=True,\n",
    "\t\t\tseed=self.hparams.seed\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = io.load_data(self.hparams.input_path, test_dates, case_study_max, indices_one, indices_zero, available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X, Y, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:79\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(topdir, dates, case_study_max, indices, indices_zero, available_models)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#print(date)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m available_models:\n\u001b[0;32m---> 79\u001b[0m     _mdl_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     _mdl_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mhstack((_mdl_data,np\u001b[38;5;241m.\u001b[39mzeros((_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))) \u001b[38;5;241m-\u001b[39m _mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])))) \u001b[38;5;66;03m# **update:** this was hardcoded as (96, 12) [12 supposed to be 128]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     _mdl_data[indices_zero] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:29\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(topdir, model_name, date, case_study_max)\u001b[0m\n\u001b[1;32m     27\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m topdir\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m model_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_data \u001b[38;5;241m/\u001b[39m case_study_max\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI'"
     ]
    }
   ],
   "source": [
    "X, Y, _, _ = io.load_data(input_path, all_dates, case_study_max, indices_one, indices_zero, available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extreme_ds \u001b[38;5;241m=\u001b[39m \u001b[43mExtremeDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mExtremeDataset.__init__\u001b[0;34m(self, split_idx, transform, seed, input_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m all_dates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([extreme_events, not_extreme_events])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(extreme_events)), torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(not_extreme_events))])\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 23\u001b[0m X, Y, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mindices_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_models\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m((torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Y)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m     26\u001b[0m                   torch\u001b[38;5;241m.\u001b[39mfrom_numpy(all_dates)), transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:79\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(topdir, dates, case_study_max, indices, indices_zero, available_models)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#print(date)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m available_models:\n\u001b[0;32m---> 79\u001b[0m     _mdl_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     _mdl_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mhstack((_mdl_data,np\u001b[38;5;241m.\u001b[39mzeros((_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))) \u001b[38;5;241m-\u001b[39m _mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])))) \u001b[38;5;66;03m# **update:** this was hardcoded as (96, 12) [12 supposed to be 128]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     _mdl_data[indices_zero] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/rainfall-prediction/utils/io.py:29\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(topdir, model_name, date, case_study_max)\u001b[0m\n\u001b[1;32m     27\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m topdir\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m model_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_data \u001b[38;5;241m/\u001b[39m case_study_max\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI'"
     ]
    }
   ],
   "source": [
    "extreme_ds = ExtremeDataset(1, input_path=input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repetitions = 5\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from training import get_model\n",
    "from utils.datasets import ExtremeDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "results = pd.DataFrame(columns=[\"split\", \"model\", \"RMSE\", \"AUROC\", \"AUPR_out\", \"AUPR_in\"])\n",
    "for split in trange(9):\n",
    "    extreme_ds = ExtremeDataset(split, input_path=Path('/home/smonaco/rainfall-prediction/data/24h_10mmMAX_OI'))\n",
    "    extreme_dl = DataLoader(extreme_ds, batch_size=len(extreme_ds), shuffle=True)\n",
    "    for model in tqdm(['unet', 'sde_unet', 'ensemble_unet', 'mcd_unet'], leave=False):\n",
    "        checkpoint_path = f\"lightning_logs/{model}/split_{split}/\"\n",
    "        if not checkpoint_path.exists():\n",
    "            # print(f\"\\n>> Skipping model {model} for split {split}\")\n",
    "            continue\n",
    "\n",
    "        ckpt = list(checkpoint_path.glob(\"*.ckpt\"))\n",
    "        assert len(ckpt) == 1\n",
    "        ckpt = ckpt[0]\n",
    "        model = get_model(model).load_from_checkpoint(ckpt)\n",
    "        model.eval()\n",
    "        print(model.device); foo\n",
    "        \n",
    "        x, y, ev_date, extremeev_label = next(iter(extreme_dl))\n",
    "        x, y = x.to(model.device), y.to(model.device)\n",
    "        pred_mean, pred_variance = model.multiple_eval(x, num_repetitions=num_repetitions)\n",
    "\n",
    "        rmse = calc_RMSE(pred_mean, y)\n",
    "        auroc = calc_AUROC(pred_variance, extremeev_label)\n",
    "        aupr_out = calc_AUPR_out(pred_variance, extremeev_label)\n",
    "        aupr_in = calc_AUPR_in(pred_variance, extremeev_label)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame({\n",
    "            \"model\": model, \"split\": split, \"RMSE\": rmse, \"AUROC\": auroc, \"AUPR_out\": aupr_out, \"AUPR_in\": aupr_in\n",
    "        })])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.metrics = edict()\n",
    "    \n",
    "    def __call__(self, y_true, y_pred, model=None, split=None, **kwargs):\n",
    "        if model not in self.models:\n",
    "            self.models.append(model)\n",
    "            self.metrics[model] = edict()\n",
    "            self.metrics[model][split] = self.metric_func(y_true, y_pred, **kwargs)\n",
    "        else:\n",
    "            if split not in self.metrics[model]:\n",
    "                self.metrics[model][split] = self.metric_func(y_true, y_pred, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Model {model} and split {split} already exists\")\n",
    "            \n",
    "\n",
    "class RMSE(Metrics):\n",
    "    def metric_func(self, y_true, y_pred):\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class AUROC(Metrics):\n",
    "    def metric_func(self, y_true, y_pred, isother=None):\n",
    "        # isother is a bool array saying for each sample if it is OoD\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_class_dl = RainDataset() # contains image and ground truth of the OoD samples\n",
    "out_of_class_dl = DataLoader(out_of_class_dl, batch_size=1, shuffle=False)\n",
    "\n",
    "all_models = {\n",
    "    'unet': [...],\n",
    "    'mcd_unet': [...],\n",
    "    'sde_unet': [...],\n",
    "\n",
    "}\n",
    "# This dictionary contains the models trained for each split in a list\n",
    "\n",
    "\n",
    "\n",
    "for batch_id, data in enumerate(out_of_class_dl):\n",
    "    image, target_img = data\n",
    "    image = image.to(device)\n",
    "    target_img = target_img.to(device)\n",
    "    for model in all_models:\n",
    "        for i, mi in enumerate(all_models[model]):\n",
    "            mi.eval()\n",
    "            with torch.no_grad():\n",
    "                output = mi(image) # regression image of dimensions equal to the target\n",
    "                RMSE.update(output, target_img, model=model, split=i)\n",
    "                AUROC.update(output, target_img, model=model, split=i)\n",
    "                AUPRC.update(output, target_img, model=model, split=i)\n",
    "                MAE.update(output, target_img, model=model, split=i)\n",
    "        AUROC.aggregate(model=model)\n",
    "        AUPRC.aggregate(model=model)\n",
    "        \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xtreme events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 45 45 405\n",
      "315 59 48 405\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "File /media/monaco/DATA1/case_study/24h_10mmMAX_OI/models/bol00_20220606_0024_regrid.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m x_train, y_train, in_features, out_features \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mload_data(input_path, train_dates, case_study_max, indices_one, indices_zero, available_models)\n\u001b[1;32m     25\u001b[0m x_val, y_val, in_features, out_features \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mload_data(input_path, val_dates, case_study_max, indices_one, indices_zero, available_models)\n\u001b[0;32m---> 26\u001b[0m x_test, y_test, in_features, out_features \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MultimodelPreci/scripts_simone/utils/io.py:75\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(topdir, dates, case_study_max, indices, indices_zero, available_models)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#print(date)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m available_models:\n\u001b[0;32m---> 75\u001b[0m     _mdl_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     _mdl_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mhstack((_mdl_data,np\u001b[38;5;241m.\u001b[39mzeros((_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(_mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))) \u001b[38;5;241m-\u001b[39m _mdl_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])))) \u001b[38;5;66;03m# **update:** this was hardcoded as (96, 12) [12 supposed to be 128]\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     _mdl_data[indices_zero] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/MultimodelPreci/scripts_simone/utils/io.py:25\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(topdir, model_name, date, case_study_max)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(topdir: \u001b[38;5;28mstr\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m, date: \u001b[38;5;28mstr\u001b[39m, case_study_max: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     24\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(topdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0024_regrid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_data \u001b[38;5;241m/\u001b[39m case_study_max\n",
      "\u001b[0;31mAssertionError\u001b[0m: File /media/monaco/DATA1/case_study/24h_10mmMAX_OI/models/bol00_20220606_0024_regrid.csv does not exist"
     ]
    }
   ],
   "source": [
    "input_path = Path('/media/monaco/DATA1/case_study')\n",
    "n_split = 8\n",
    "case_study = '24h_10mmMAX_OI'\n",
    "input_path = input_path / case_study\n",
    "use_extreme = False\n",
    "\n",
    "case_study_max, available_models, train_dates, val_dates, test_dates, indices_one, indices_zero, mask, nx, ny = io.get_casestudy_stuff(\n",
    "    input_path, n_split, case_study=case_study, ispadded=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(len(train_dates), len(val_dates), len(test_dates), sum(len(x) for x in [train_dates, val_dates, test_dates]))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_dates1 = pd.concat([pd.read_csv(exev, header=None) for exev in input_path.glob('*extremeEvents.csv')])[0].values\n",
    "train_dates = np.array(list(set(train_dates).union(val_dates).union(test_dates).difference(test_dates1)))\n",
    "train_dates, val_dates = train_test_split(train_dates, train_size=315, random_state=42)\n",
    "test_dates = test_dates1\n",
    "print(len(train_dates), len(val_dates), len(test_dates), sum(len(x) for x in [train_dates, val_dates, test_dates])-17)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train, in_features, out_features = io.load_data(input_path, train_dates, case_study_max, indices_one, indices_zero, available_models)\n",
    "x_val, y_val, in_features, out_features = io.load_data(input_path, val_dates, case_study_max, indices_one, indices_zero, available_models)\n",
    "x_test, y_test, in_features, out_features = io.load_data(input_path, test_dates, case_study_max, indices_one, indices_zero, available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr\n",
      "vl\n",
      "ts\n",
      ">> 20220606\n",
      ">> 20220701\n",
      ">> 20220727\n",
      ">> 20220809\n",
      ">> 20220906\n",
      ">> 20220909\n",
      ">> 20220928\n",
      ">> 20221001\n",
      ">> 20221223\n",
      ">> 20230413\n",
      ">> 20230516\n",
      ">> 20230703\n",
      ">> 20230825\n",
      ">> 20230912\n",
      ">> 20231113\n",
      ">> 20231114\n",
      ">> 20240318\n"
     ]
    }
   ],
   "source": [
    "for n, sp in zip(['tr', 'vl', 'ts'], [train_dates, val_dates, test_dates]):\n",
    "    print(n)\n",
    "    for d in sp:\n",
    "        if not Path(f\"/media/monaco/DATA1/case_study/24h_10mmMAX_OI/models/bol00_{d}_0024_regrid.csv\").exists():\n",
    "            print('>>', d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
